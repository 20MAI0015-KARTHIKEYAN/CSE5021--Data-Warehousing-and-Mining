{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DWM TEXT MINING FROM TWITTER.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aJ1EvmFwb11"
      },
      "source": [
        "EXAMPLE FOR API BASED TEXT MINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI67CIvDQnCu"
      },
      "source": [
        "importing the reqires libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA9Q4MFGB4Yr"
      },
      "source": [
        "from tweepy import API \n",
        "from tweepy import Cursor\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7jalVY7Qsfv"
      },
      "source": [
        "Twitter API Keys as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWHLlc_GB-mw"
      },
      "source": [
        "#API KEYS PROVIDED BY TWITTER\n",
        "API_KEY = \"pse5QOaNqCk1TKz7cBR5UdiMA\"\n",
        "API_SECRET = \"hYOkDIae7FBArDQJ2pEHfN6h2UVvEXqjO58zAyzNsL5JUsFLNj\"\n",
        "ACCESS_TOKEN = \"1198200370440196096-1e0lZUiWXAxG8GEY4qjHSGX8cJh0IW\"\n",
        "ACCESS_TOKEN_SECRET = \"nFCx1dwiYfkrStff88F92Du1U0nyCYMycPH7hfmmzycjs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV_tOl4gQxrK"
      },
      "source": [
        "Datastructure Creation to accept data from the website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc5EpV8pB_-r"
      },
      "source": [
        "class TwitterClient():\n",
        "  def __init__(self, twitter_user=None):\n",
        "    self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
        "    self.twitter_client = API(self.auth)\n",
        "    self.twitter_user = twitter_user\n",
        "\n",
        "  def get_twitter_client_api(self):\n",
        "      return self.twitter_client\n",
        "\n",
        "  def get_user_timeline_tweets(self, num_tweets):\n",
        "      tweets = []\n",
        "      for tweet in Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
        "          tweets.append(tweet)\n",
        "      return tweets\n",
        "\n",
        "  def get_friend_list(self, num_friends):\n",
        "      friend_list = []\n",
        "      for friend in Cursor(self.twitter_client.friends, id=self.twitter_user).items(num_friends):\n",
        "          friend_list.append(friend)\n",
        "      return friend_list\n",
        "\n",
        "  def get_home_timeline_tweets(self, num_tweets):\n",
        "      home_timeline_tweets = []\n",
        "      for tweet in Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n",
        "          home_timeline_tweets.append(tweet)\n",
        "      return home_timeline_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PICqoysDQ8AQ"
      },
      "source": [
        "Authenticator class to enable the tunnel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEND5YQOCBlj"
      },
      "source": [
        "class TwitterAuthenticator():\n",
        "  def authenticate_twitter_app(self):\n",
        "      auth = OAuthHandler(API_KEY, API_SECRET)\n",
        "      auth.set_access_token(ACCESS_TOKEN,ACCESS_TOKEN_SECRET)\n",
        "      return auth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B3M4bbPRGUp"
      },
      "source": [
        "Text Preprocessing Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8nWeX5fCD2v"
      },
      "source": [
        "class TwitterStreamer():\n",
        "  def __init__(self):\n",
        "    self.twitter_autenticator = TwitterAuthenticator()    \n",
        "\n",
        "  def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
        "    # This handles Twitter authetification and the connection to Twitter Streaming API\n",
        "    listener = TwitterListener(fetched_tweets_filename)\n",
        "    auth = self.twitter_autenticator.authenticate_twitter_app() \n",
        "    stream = Stream(auth, listener)\n",
        "\n",
        "    # This line filter Twitter Streams to capture data by the keywords: \n",
        "    stream.filter(track=hash_tag_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja_-dLU2RRkc"
      },
      "source": [
        "Listener class to print the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tDvEcODKYD8"
      },
      "source": [
        "# # # # TWITTER STREAM LISTENER # # # #\n",
        "class TwitterListener(StreamListener):\n",
        "    \"\"\"\n",
        "    This is a basic listener that just prints received tweets to stdout.\n",
        "    \"\"\"\n",
        "    def __init__(self, fetched_tweets_filename):\n",
        "        self.fetched_tweets_filename = fetched_tweets_filename\n",
        "\n",
        "    def on_data(self, data):\n",
        "        try:\n",
        "            print(data)\n",
        "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
        "                tf.write(data)\n",
        "            return True\n",
        "        except BaseException as e:\n",
        "            print(\"Error on_data %s\" % str(e))\n",
        "        return True\n",
        "          \n",
        "    def on_error(self, status):\n",
        "        if status == 420:\n",
        "            # Returning False on_data method in case rate limit occurs.\n",
        "            return False\n",
        "        print(status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvYuH015RaJg"
      },
      "source": [
        "Sentiment Analyser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SXhcOewKuVj"
      },
      "source": [
        "class TweetAnalyzer():\n",
        "    \"\"\"\n",
        "    Functionality for analyzing and categorizing content from tweets.\n",
        "    \"\"\"\n",
        " \n",
        "    def clean_tweet(self, tweet):\n",
        "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        " \n",
        "    def analyze_sentiment(self, tweet):\n",
        "        analysis = TextBlob(self.clean_tweet(tweet))\n",
        "        \n",
        "        if analysis.sentiment.polarity > 0:\n",
        "            return 1\n",
        "        elif analysis.sentiment.polarity == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return -1\n",
        " \n",
        "    def tweets_to_data_frame(self, tweets):\n",
        "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['tweets'])\n",
        " \n",
        "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
        "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
        "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
        "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
        "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
        "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
        " \n",
        "        return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6vwr0Z5RdzN"
      },
      "source": [
        "Main block to pull data from twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oJ7CWIfKx55",
        "outputId": "c064738d-9321-4b29-bddc-3224f0a0ff07"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    twitter_client = TwitterClient()\n",
        "    tweet_analyzer = TweetAnalyzer()\n",
        "\n",
        "    api = twitter_client.get_twitter_client_api()\n",
        "\n",
        "    tweets = api.user_timeline(screen_name=\"the_hindu\", count=1000)\n",
        "\n",
        "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
        "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
        "\n",
        "    print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                tweets  ...  sentiment\n",
            "0    Experts flag lack of published data on perform...  ...          0\n",
            "1    Prime Minister #NarendraModi will not attend t...  ...          0\n",
            "2    With experts warning of a third wave as well, ...  ...          1\n",
            "3    Shifting of a COVID-19 patient from Delhi to C...  ...          1\n",
            "4    At present, Goods and Services Tax is levied a...  ...          0\n",
            "..                                                 ...  ...        ...\n",
            "195  U.S. regulators authorised #Pfizer and BioNTec...  ...          1\n",
            "196  Mr. Johnson, who was buoyed by successful loca...  ...          1\n",
            "197  More than 100 churches have signed up to host ...  ...          1\n",
            "198  Pakistan was put on the grey list by the Paris...  ...          1\n",
            "199  CITU leaders Ch. Ammannaidu urged Collector J....  ...          0\n",
            "\n",
            "[200 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD7HoiHcRpne"
      },
      "source": [
        "Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UjBbmoBK8Kk"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PwEqxbjRsu9"
      },
      "source": [
        "Porter - Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnJVHaGyLL8Z"
      },
      "source": [
        "def porter_stemmer_tokenizer(text):\n",
        "  return[porter.stem(word) for word in text.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6EqxoamRxEx"
      },
      "source": [
        "Porter - Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ngiz_1OL6y"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, tokenizer = porter_stemmer_tokenizer, use_idf = True, norm = 'l2', smooth_idf = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWTMTj7iR0D0"
      },
      "source": [
        "Porter - Categorizing the target and dependent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqjgMi7FONhE"
      },
      "source": [
        "X = tfidf.fit_transform(df.tweets)\n",
        "Y = df.sentiment.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8uEeqdxR-yS"
      },
      "source": [
        "Porter - Splitting the test and Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blmOPTwkOUXZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test =train_test_split(X, Y, random_state=1, test_size=0.1, shuffle= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIwTzyf-SFC8"
      },
      "source": [
        "Porter - Performing Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZRBFpEOb6t"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "logitCV = LogisticRegressionCV( cv=5, scoring='accuracy', max_iter=500 ).fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqC1V2wJSIPf"
      },
      "source": [
        "Accuracy score of Porter stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDiF9NPOmX7",
        "outputId": "e9c13e89-db48-4619-8766-ddb2da224d98"
      },
      "source": [
        "logitCV.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHczWPJMSNlx"
      },
      "source": [
        "Lancaster stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd3IMua7Oq7g"
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lancaster=LancasterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_FVzHp8SWk-"
      },
      "source": [
        "Lancaster - Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMKp8nmyPXjd"
      },
      "source": [
        "def lancaster_stemmer_tokenizer(text):\n",
        "  return[lancaster.stem(word) for word in text.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVDg1he6SZrE"
      },
      "source": [
        "Lancaster - Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeI_iIZ9PxM7"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, tokenizer = lancaster_stemmer_tokenizer, use_idf = True, norm = 'l2', smooth_idf = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WSSchxxSphg"
      },
      "source": [
        "Lancaster - Categorizing the target and dependent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CygB2-aAP3Wz"
      },
      "source": [
        "X = tfidf.fit_transform(df.tweets)\n",
        "Y = df.sentiment.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-xHbmqhS059"
      },
      "source": [
        "Lancaster - Splitting the test and Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqp_-P7nP52f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test =train_test_split(X, Y, random_state=1, test_size=0.1, shuffle= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ27OsqsTA3u"
      },
      "source": [
        "Lancaster - Performing Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6icD0sjQF_P"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "logitCV = LogisticRegressionCV( cv=5, scoring='accuracy', max_iter=500 ).fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fBvDTxRSP-J"
      },
      "source": [
        "Accuracy score of Lancaster stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9MEYAiPQHsY",
        "outputId": "41365a8d-9509-4bb7-b0e0-5212ad4c1578"
      },
      "source": [
        "logitCV.score(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}