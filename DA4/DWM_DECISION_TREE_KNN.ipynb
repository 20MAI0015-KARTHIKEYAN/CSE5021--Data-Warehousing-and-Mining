{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DWM_DECISION_TREE_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XJ_3-L0WzP1"
      },
      "source": [
        "# DECISION TREE AND K NEAREST NEIGHBOUR IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vK82kB-W7Te"
      },
      "source": [
        "REG NO: 20MAI0015"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s_LXvXRZTKU"
      },
      "source": [
        "DATASET : https://www.kaggle.com/kazanova/sentiment140/download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKubQUOzAAUB"
      },
      "source": [
        "import numpy as numpy\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtCDY-g4Jmb9"
      },
      "source": [
        "To visualize the data in the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkwWUHIEDYU2"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h6mTzKLDZzb"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.utils import shuffle \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s_Cv6oNJkdo"
      },
      "source": [
        "NLP Preprocessing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ISPGdrXDbK-"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ZyRdK0DgCS"
      },
      "source": [
        "import re\n",
        "import random\n",
        "import gensim"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4NnHxbjDgWs"
      },
      "source": [
        "\n",
        "from collections import Counter\n",
        "import unicodedata as udata\n",
        "import string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tos8BVInDhbg",
        "outputId": "3dee03e8-d6b1-484f-954c-d6fa3590f2fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxS_zbz2HYn-"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/tw_data.csv\", encoding='latin-1', header=None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL6ZpNNvJga7"
      },
      "source": [
        "\n",
        "Reading csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0u1UKx9HkoU"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtiAwA0OJpaX"
      },
      "source": [
        "Give column names - \n",
        "Assigning the Columns name to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5llyW2JarE"
      },
      "source": [
        "df.columns = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWXS5fJEJs5c",
        "outputId": "c0331421-8617-438b-a154-6360fa4524b4"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentiment', 'id', 'date', 'query', 'user', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJQeROFcJ00n"
      },
      "source": [
        "Checking Null values in the dataset. Here we are counting each cloumn null values in the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFJBPhjJJwmb",
        "outputId": "973f9712-f71c-49c5-b305-d8b5a20415ef"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment    0\n",
              "id           0\n",
              "date         0\n",
              "query        0\n",
              "user         0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-as-x9tJ58G"
      },
      "source": [
        "Checking the duplicates values and counting duplicates in the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgM1mOzRKCCK",
        "outputId": "9d3e1043-c33f-4d41-f23a-a690cbac0a31"
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "igTetC_AJ5qJ",
        "outputId": "27d3813d-b7fe-46c8-c7fb-9c0610e0c567"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1962713567</td>\n",
              "      <td>Fri May 29 11:31:06 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>fashionchalet</td>\n",
              "      <td>@beach_bot @WeWereDamsels thanks, lovelies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>1685759862</td>\n",
              "      <td>Sun May 03 01:56:23 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>jessixcouture</td>\n",
              "      <td>@mikeziemer take our tears put em on ice..caus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2187450426</td>\n",
              "      <td>Mon Jun 15 20:17:59 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>kingivn</td>\n",
              "      <td>Wow I just passed bye my block AVE D IS SO QUI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2050418273</td>\n",
              "      <td>Fri Jun 05 18:38:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>samvlcek</td>\n",
              "      <td>got my black heels&amp;amp;nails and a blue dress ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2016418864</td>\n",
              "      <td>Wed Jun 03 06:44:40 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>missandree</td>\n",
              "      <td>@danasmuse Good luck! Have a nice day</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          4  ...        @beach_bot @WeWereDamsels thanks, lovelies \n",
              "1          4  ...  @mikeziemer take our tears put em on ice..caus...\n",
              "2          0  ...  Wow I just passed bye my block AVE D IS SO QUI...\n",
              "3          4  ...  got my black heels&amp;nails and a blue dress ...\n",
              "4          4  ...             @danasmuse Good luck! Have a nice day \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZY6lIUWJyLt"
      },
      "source": [
        "df = df.drop([\"id\", \"date\", \"query\", \"user\"], axis = 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "mYNhkQQsKGJ_",
        "outputId": "019d4b9c-3785-479e-baf2-5aa0b47a2c46"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>@beach_bot @WeWereDamsels thanks, lovelies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>@mikeziemer take our tears put em on ice..caus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Wow I just passed bye my block AVE D IS SO QUI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>got my black heels&amp;amp;nails and a blue dress ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@danasmuse Good luck! Have a nice day</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          4        @beach_bot @WeWereDamsels thanks, lovelies \n",
              "1          4  @mikeziemer take our tears put em on ice..caus...\n",
              "2          0  Wow I just passed bye my block AVE D IS SO QUI...\n",
              "3          4  got my black heels&amp;nails and a blue dress ...\n",
              "4          4             @danasmuse Good luck! Have a nice day "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ortD9PSYKHyB",
        "outputId": "690d2314-097f-4504-a459-72c41258c166"
      },
      "source": [
        "df.sentiment.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Bco3dAKOUK"
      },
      "source": [
        "Cleaning data -- \n",
        "add new column pre_clean_len to dataframe which is length of each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElvaB4XeKJDe"
      },
      "source": [
        "df['pre_clean_len'] = [len(t) for t in df.text]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpG_vgt4KUbM"
      },
      "source": [
        "Finding outliers using Box plot using pre_clean_len column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sxNdfKZ6KRgb",
        "outputId": "4a55ae04-ecf7-4d6f-dfad-bb85117ee8cf"
      },
      "source": [
        "plt.boxplot(df.pre_clean_len)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSQlrvrbKaz3"
      },
      "source": [
        "\n",
        "check for any tweets greater than 140 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "VmO5UGmBKYDR",
        "outputId": "57ee1390-172d-4d67-b8a1-6102007dd671"
      },
      "source": [
        "df[df.pre_clean_len > 140].head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>pre_clean_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>4</td>\n",
              "      <td>My dogs are adorable! One's crashed on the cou...</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>4</td>\n",
              "      <td>Ok I'm going back to sleep... Gimme a few more...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>4</td>\n",
              "      <td>A direct quote from a coworker: &amp;quot;its almo...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>4</td>\n",
              "      <td>@chri5784 flushes drive me nuts (like that whe...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>4</td>\n",
              "      <td>@ScottATaylor  Pretty good, thanks!  I'm half ...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>4</td>\n",
              "      <td>okay tweeps, i rlly need yr help by hitting up...</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>0</td>\n",
              "      <td>Oh no! our pet garter snake has vitamin B defi...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>4</td>\n",
              "      <td>@JodiCleghorn That would be cool. Currently I ...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>4</td>\n",
              "      <td>part of my more serious &amp;quot;twitter&amp;quot; to...</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>4</td>\n",
              "      <td>Listening to: 50 Cent - I Get Money ...I FORGO...</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentiment  ... pre_clean_len\n",
              "54           4  ...           142\n",
              "139          4  ...           147\n",
              "168          4  ...           141\n",
              "323          4  ...           141\n",
              "393          4  ...           147\n",
              "457          4  ...           141\n",
              "472          0  ...           147\n",
              "691          4  ...           146\n",
              "853          4  ...           156\n",
              "894          4  ...           142\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHx6YJEdKecn"
      },
      "source": [
        "**removing outlier tweets**\n",
        "\n",
        "Cleaning operations\n",
        "\n",
        "Importing beautiful \n",
        "\n",
        "remove @ mentions from tweets\n",
        "\n",
        "remove URLs from tweets\n",
        "\n",
        "converting words like isn't to is not\n",
        "\n",
        "get only text from the tweets\n",
        "\n",
        "remove utf-8-sig code\n",
        "\n",
        "converting all into lower case\n",
        "\n",
        "will replace non-alphabetic characters by space\n",
        "\n",
        "Word Punct Tokenize and only consider \n",
        "\n",
        "words whose length is greater than 1\n",
        "\n",
        "join the words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN-rnjdzKZ0Y"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieS6AopRQ7k8"
      },
      "source": [
        "pat1 = r'@[A-Za-z0-9_]+'        # remove @ mentions from tweets\n",
        "pat2 = r'https?://[^ ]+'        # remove URLs from tweets\n",
        "combined_pat = r'|'.join((pat1, pat2)) #addition of pat1 and pat2\n",
        "www_pat = r'www.[^ ]+'         # remove URLs from tweets\n",
        "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",   # converting words like isn't to is not\n",
        "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                \"mustn't\":\"must not\"}\n",
        "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ1hQ_P-Q9_r"
      },
      "source": [
        "def tweet_cleaner(text):  # define tweet_cleaner function to clean the tweets\n",
        "    soup = BeautifulSoup(text, 'lxml')    # create beautiful soup object\n",
        "    souped = soup.get_text()   # get only text from the tweets \n",
        "    try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")    # remove utf-8-sig code\n",
        "    except:\n",
        "        bom_removed = souped\n",
        "    stripped = re.sub(combined_pat, '', bom_removed) # calling combined_pat\n",
        "    stripped = re.sub(www_pat, '', stripped) #remove URLs\n",
        "    lower_case = stripped.lower()      # converting all into lower case\n",
        "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case) # converting words like isn't to is not\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)       # will replace # by space\n",
        "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1] # Word Punct Tokenize and only consider words whose length is greater than 1\n",
        "    return (\" \".join(words)).strip() # join the words"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvJgsoyqQ_3T",
        "outputId": "dba0f901-130d-4ceb-b889-af4eb6e9a115"
      },
      "source": [
        "#Note that we have 1600000 instances. But processing so many instances will take a very very long time.\n",
        "#Hence, restricting to rather 50000 instances.\n",
        "limit=50000\n",
        "import time; \n",
        "ms = time.time()\n",
        "#nums = [0,400000,800000,1200000,1600000] # used for batch processing tweets\n",
        "#nums = [0, 9999]\n",
        "clean_tweet_texts = [] # initialize list\n",
        "for i in range(0,limit): # batch process 1.6 million tweets \n",
        "    if i % 10000==0:\n",
        "        print(i, time.time()-ms)\n",
        "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))  # call tweet_cleaner function and pass parameter as all the tweets to clean the tweets and append cleaned tweets into clean_tweet_texts list"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 8.058547973632812e-05\n",
            "10000 2.648667335510254\n",
            "20000 5.2080605030059814\n",
            "30000 7.761733770370483\n",
            "40000 10.356648445129395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NjgVr_aSNM6"
      },
      "source": [
        "clean tweet texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp7IkcxzSMsV",
        "outputId": "68656334-36a5-4a41-a7f6-3111782fb8be"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN_UWk6mSTM-"
      },
      "source": [
        "tokenize word in clean_tweet_texts and append it to word_tokens list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agLZGb2-RCab"
      },
      "source": [
        "word_tokens = [] # initialize list for tokens\n",
        "for word in clean_tweet_texts:  # for each word in clean_tweet_texts\n",
        "    word_tokens.append(word_tokenize(word)) #tokenize word in clean_tweet_texts and append it to word_tokens list"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0M0oiJ7SYi4"
      },
      "source": [
        "\n",
        "Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzOsIm4rSVLy",
        "outputId": "812581bd-9799-49ed-a076-1ed288db35a4"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngK9RhY-SaUK"
      },
      "source": [
        "df1 = [] # initialize list df1 to store words after lemmatization\n",
        "from nltk.stem import WordNetLemmatizer # import WordNetLemmatizer from nltk.stem\n",
        "lemmatizer = WordNetLemmatizer() # create an object of WordNetLemmatizer\n",
        "for l in word_tokens: # for loop for every tokens in word_token\n",
        "    b = [lemmatizer.lemmatize(q) for q in l] #for every tokens in word_token lemmatize word and giev it to b\n",
        "    df1.append(b) #append b to list df1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDTbpbpfScZ4"
      },
      "source": [
        "clean_df1 =[] # initialize list clean_df1 to join word tokens after lemmatization\n",
        "for c in df1:  # for loop for each list in df1\n",
        "    a = \" \".join(c) # join words in list with space in between and give it to a\n",
        "    clean_df1.append(a) # append a to clean_df1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTtGq97Sh9k"
      },
      "source": [
        "Cleaning df_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDLWzrkSfMu"
      },
      "source": [
        "clean_df = pd.DataFrame(clean_df1,columns=['text']) # convert clean_tweet_texts into dataframe and name it as clean_df\n",
        "#clean_df['target'] = df.sentiment[:10000] # from earlier dataframe get the sentiments of each tweet and make a new column in clean_df as target and give it all the sentiment score\n",
        "#clean_df"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1akU559SmOo"
      },
      "source": [
        "clean_df['clean_len'] = [len(t) for t in clean_df.text] # Again make a new coloumn in the dataframe and name it as clean_len which"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "X-NrF3orSnpC",
        "outputId": "c8770608-2695-4eff-e033-0c85bdc8788e"
      },
      "source": [
        "target2 = [] # initialize list\n",
        "for i in range(0,limit): # batch process 1.6 million tweets \n",
        "    target2.append(df['sentiment'][i])\n",
        "clean_df['target']=target2\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>pre_clean_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>@beach_bot @WeWereDamsels thanks, lovelies</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>@mikeziemer take our tears put em on ice..caus...</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Wow I just passed bye my block AVE D IS SO QUI...</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>got my black heels&amp;amp;nails and a blue dress ...</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@danasmuse Good luck! Have a nice day</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text  pre_clean_len\n",
              "0          4        @beach_bot @WeWereDamsels thanks, lovelies              43\n",
              "1          4  @mikeziemer take our tears put em on ice..caus...            100\n",
              "2          0  Wow I just passed bye my block AVE D IS SO QUI...            134\n",
              "3          4  got my black heels&amp;nails and a blue dress ...             98\n",
              "4          4             @danasmuse Good luck! Have a nice day              38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k70Iv5_zStHC",
        "outputId": "21cb6e5b-e5b0-4bd1-a7ef-2f0f5e394579"
      },
      "source": [
        "X = clean_df.text # get all the text in x variable\n",
        "y = clean_df.target # get all the sentiments into y variable\n",
        "print(X.shape) #print shape of x\n",
        "print(y.shape) # print shape of y\n",
        "from collections import Counter\n",
        "print(set(y)) # equals to list(set(words))\n",
        "print(Counter(y).values())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000,)\n",
            "(50000,)\n",
            "{0, 4}\n",
            "dict_values([24903, 25097])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceq3k_cASxiy"
      },
      "source": [
        "Perform train and test split\n",
        "\n",
        "X_train is the tweets of training data, X_test is the testing tweets which we have to predict, y_train is the sentiments of tweets in the traing data and y_test is the sentiments of the tweets which we will use to measure the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHLw1xhXSvs1"
      },
      "source": [
        "from sklearn.model_selection  import train_test_split #from sklearn.cross_validation import train_test_split to split the data into training and tesing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state= 1) # split the data into traing and testing set where ratio is 80:20"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHYyyvNKS9Lf"
      },
      "source": [
        "\n",
        "Get Tf-idf object and save it as vect. We can select features from here we just have simply change\n",
        "the ngram range to change the features also we can remove stop words over here with the help of stop parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeIYbRDDS2N2"
      },
      "source": [
        "vect = TfidfVectorizer(analyzer = \"word\", ngram_range=(1,3))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMqw8CCETDfS"
      },
      "source": [
        "fit or training data tweets to vect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzFL6DO3TAty"
      },
      "source": [
        "vect.fit(X_train) \n",
        "X_train_dtm = vect.transform(X_train)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76hDjG9_TF4v"
      },
      "source": [
        "X_test_dtm = vect.transform(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skZLCBLlTLt6"
      },
      "source": [
        "## **DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnLthj3PVsDk"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_dtc = DecisionTreeClassifier(random_state = 100, max_depth=3, min_samples_leaf=5)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-3RPlgyWHlR",
        "outputId": "a9e45917-e3c0-4602-b0fc-eaefb692a9ea"
      },
      "source": [
        "clf_dtc.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=5, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=100, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjSaJMo-WIw3",
        "outputId": "0e4428e4-d727-495d-e964-62f4303bbc7e"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score \n",
        "accuracies = cross_val_score(estimator = clf_dtc, X = X_train_dtm, y = y_train, cv = 10)\n",
        "accuracies.mean()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.582475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGYsnfYLWKCn"
      },
      "source": [
        "y_pred_dtc = clf_dtc.predict(X_test_dtm)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ9HY0WZWLJi",
        "outputId": "9aafe7c3-2d40-42a6-96b7-9a355a502816"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_dtc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DBaOisYYCdS"
      },
      "source": [
        "## **Decision Tree Accuracy - 0.5818**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-q9fXWzWMZB",
        "outputId": "4c134eeb-a544-48d6-e302-fad9689be8ce"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred_dtc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1305, 3763],\n",
              "       [ 419, 4513]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOhWxkiXWSiJ"
      },
      "source": [
        "#K Nearest Neighbour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3mTBOaiWN4N"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NbFKoVFWxq6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q-k6WfDWVN8",
        "outputId": "0dc9749d-497b-4330-9aa9-fb3fcbd55c29"
      },
      "source": [
        "clf_knn.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_DP1mt4WWin",
        "outputId": "640ff07c-01a5-4a0b-f939-d308a18569e1"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score \n",
        "accuracies = cross_val_score(estimator = clf_knn, X = X_train_dtm, y = y_train, cv = 10)\n",
        "accuracies.mean()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.516075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1znKGqWWZJu"
      },
      "source": [
        "y_pred_knn = clf_knn.predict(X_test_dtm)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG3qe23sWbFc",
        "outputId": "57089e85-b5b5-41d9-eadd-8f4e13c55ae3"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_knn)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m39Jf9ZuX7tj"
      },
      "source": [
        "# **KNN ACCURACY** - 0.5226\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blWXJNDEWc0d",
        "outputId": "b41ae939-7f94-42b9-e84a-9c5df9e73dd2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred_knn)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1978, 3090],\n",
              "       [1684, 3248]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETwU9zzSWesW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}